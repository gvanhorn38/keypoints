RANDOM_SEED : 1.0

SESSION_CONFIG : {
  PER_PROCESS_GPU_MEMORY_FRACTION : 0.95
}

PARTS : {
 NUM_PARTS : 17,
 PART_LOSS_ALPHA : 100,
 VIS_LOSS_ALPHA : 100,
 LEFT_RIGHT_PAIRS : [
  [1, 2], # eyes
  [3, 4], # ears
  [5, 6], # shoulder
  [7, 8], # elbow
  [9, 10], # wrist
  [11, 12], # hip
  [13, 14], # knee
  [15, 16], # ankle
 ],
 NAMES : [
  'nose',
  'left_eye',
  'right_eye',
  'left_ear',
  'right_ear',
  'left_shoulder',
  'right_shoulder',
  'left_elbow',
  'right_elbow',
  'left_wrist',
  'right_wrist',
  'left_hip',
  'right_hip',
  'left_knee',
  'right_knee',
  'left_ankle',
  'right_ankle'
  ],
  
 COLORS : [
  "red",
  "green", 
  "blue",
  "black",
  "chartreuse",
  "darkgoldenrod",
  "darkred",
  "deeppink",
  "dimgray",
  "fuchsia",
  "lavender",
  "lightpink",
  "mediumturquoise",
  "powderblue",
  "seashell",
  "beige",
  "yellow"
 ],
 
 SYMBOLS : [
  "o",
  "o",
  "o",
  "o",
  "o",
  "o",
  "o",
  "o",
  "o",
  "o",
  "o",
  "o",
  "o",
  "o",
  "o",
  "o",
  "o"
 ],
 
 SIGMAS : [
   .026,
   .025,
   .025,
   .035,
   .035,
   .079,
   .079,
   .072,
   .072,
   .062,
   .062,
   .107,
   .107,
   .087, 
   .087,
   .089,
   .089
 ]
}

HEATMAP_SIZE : 64

###################
# Image Processing and Augmentation 

# The image will be resized to [INPUT_SIZE, INPUT_SIZE, 3]
INPUT_SIZE : 256

# Tight bounding box crops, or loose? 
LOOSE_BBOX_CROP : true
LOOSE_BBOX_PAD_FACTOR : 0.25

# Randomly flip the image left right, 50% chance of flipping
DO_RANDOM_FLIP_LEFT_RIGHT : true

# Randomly perturb the coordinates of the bounding boxes
# The fraction of time to do the shift, 0 is never, 1 is always
DO_RANDOM_BBOX_SHIFT : 0.5
# The maximum number of pixels to shift the coordinates
RANDOM_BBOX_SHIFT_EXTENT : 8 

# Color distortion
# The fraction of time to distort the color, 0 is never, 1 is always
DO_COLOR_DISTORTION : 0.25
# Avoids slower ops (random_hue and random_contrast)
COLOR_DISTORT_FAST : False

# END: Image Processing and Augmentation
###################

# Input queues to the model
NUM_INPUT_THREADS : 2
BATCH_SIZE : 4

# 77544 39935
NUM_TRAIN_EXAMPLES : 56945
NUM_TRAIN_ITERATIONS : 300000

# Learning Rate parameters
INITIAL_LEARNING_RATE : 0.01
NUM_EPOCHS_PER_DELAY : 4
LEARNING_RATE_DECAY_FACTOR : 0.94
LEARNING_RATE_STAIRCASE : true

RMSPROP_DECAY : 0.9
RMSPROP_MOMENTUM : 0
RMSPROP_EPSILON : 1.0


# Capacity of the queue producing batched examples
QUEUE_CAPACITY : 20
# Minimum size of the queue to ensure good shuffling
QUEUE_MIN :  5


# Batch normalization. Constant governing the exponential moving average of
# the 'global' mean and variance for all activations.
BATCHNORM_MOVING_AVERAGE_DECAY : 0.9997

# The decay to use for the moving average.
MOVING_AVERAGE_DECAY : 0.9999

###################
# Background Heatmap Computation

BACKGROUND_HEATMAPS
  # Add the right part to the background of the left part (and vice versa)
  ADD_TARGET_LEFT_RIGHT_PAIRS : true
  # Add the visible parts from background instances
  ADD_NON_TARGET_PARTS : true
  # For the background instances, should their occluded parts be added to the background heatmap? 
  NON_TARGET_INCLUDE_OCCLUDED : false
  # Add the right part to the background of the left part for the background instances (and vice versa)
  ADD_NON_TARGET_LEFT_RIGHT_PAIRS : true

# END Background heatmap computation
###################

###################
# Loss settings

LOSS
  # Add the scaled background heatmap to the ground truth heatmap, then compute the loss
  USE_SCALED_BACKGROUND : false
  # The scaling to apply to each predicted heatmap. The number of scales must match the number of hourglass units
  SCALE_FACTORS : [1., .5, .25, .125, .0625, .03125, .015625, 0]

  # Use the background heatmap as a cost matrix
  USE_BACKGROUND_AS_COST_MATRIX : false
  COST_MATRIX_SCALE : 1.

  # Don't take the background heatmaps into account
  NO_BACKGROUND : true

# END Loss setting
###################

# Saving models and summaries

# How often, in seconds, to save summaries.
SAVE_SUMMARY_SECS : 30

# How often, in seconds, to save the model
SAVE_INTERVAL_SECS : 3600

# The maximum number of recent checkpoint files to keep.
MAX_TO_KEEP : 3

# In addition to keeping the most recent `max_to_keep` checkpoint files, 
# you might want to keep one checkpoint file for every N hours of training
# The default value of 10,000 hours effectively disables the feature.
KEEP_CHECKPOINT_EVERY_N_HOURS : 24

# The frequency, in terms of global steps, that the loss and global step and logged.
LOG_EVERY_N_STEPS : 10
